## ğŸš€ Project Overview

The Smart Logistics Decision System aims to optimize delivery operations using data-driven decision making. The system integrates operational data, environmental factors, and predictive modeling to improve route efficiency, delivery time estimation, and cost optimization.

## ğŸ¯ Project Objectives

### 1ï¸âƒ£ Risk-Based Delay Prediction
- Build a machine learning model that predicts delivery delay probability.
- Interpret model output probability as a structured **risk score**.

### 2ï¸âƒ£ Risk Tier Classification
Convert predicted delay probability into operational risk levels:

| Probability Range | Risk Level |
|-------------------|------------|
| < 0.40            | Low Risk   |
| 0.40 â€“ 0.70       | Medium Risk|
| > 0.70            | High Risk  |
| > 0.85            | Critical Risk |

### 3ï¸âƒ£ Rule-Based Risk Overrides
Enhance ML predictions with domain-driven business logic:

- **Weather-Traffic Critical Rule:**  
  If Precipitation > 20mm AND Traffic = Heavy â†’ Risk = Critical

- **Asset Stress Rule:**  
  If Asset_Utilization > 90% â†’ Operational Risk = High

### 4ï¸âƒ£ Risk-Driven Decision Engine
Attach automated actions based on risk level:

- ğŸŸ¢ Low Risk â†’ Normal delivery  
- ğŸŸ¡ Medium Risk â†’ Monitoring + slight route optimization  
- ğŸ”´ High Risk â†’ Re-route vehicle + notify operations  
- âš« Critical Risk â†’ Immediate rerouting + AI-generated client notification + fleet redistribution  

### 5ï¸âƒ£ Simulated Optimization Logic
- Simulate route optimization by adjusting estimated delivery time.
- Simulate fleet redistribution when asset utilization exceeds safe thresholds.

### 6ï¸âƒ£ AI Communication Layer
Automatically generate customer notifications when risk is High or Critical.


## ğŸ“Š Dataset

**Base Dataset:**  
Smart Logistics Supply Chain Dataset 
https://www.kaggle.com/datasets/ziya07/smart-logistics-supply-chain-dataset

The original dataset contains shipment details, delivery timelines, geographic information, and operational attributes.

### Feature Engineering

A precipitation factor was added to the dataset using quantile-based binning to simulate weather impact on logistics performance. This allows the system to incorporate environmental conditions into delivery time and decision modeling.


## ğŸ›  Development Phases

---

## ğŸ“Š Phase 1 â€“ Data Engineering & Feature Preparation

### ğŸ¯ Objective
Transform the raw logistics dataset into a structured, model-ready dataset suitable for predictive modeling and risk analysis.

---

### ğŸ§¹ Data Cleaning

- Removed inconsistencies and invalid records  
- Standardized column formats  
- Ensured numerical consistency for modeling  
- Validated missing values and corrected data types  

---

### ğŸŒ§ Feature Engineering

Enhanced the dataset with domain-driven features:

- Generated **Precipitation (mm)** using humidity and temperature  
- Structured environmental factors (Temperature, Humidity, Precipitation)  
- Organized operational variables (Inventory Level, Waiting Time, Utilization metrics)  
- Prepared features for downstream ML modeling  

---

### ğŸ— Dataset Structuring

Separated datasets into:

- `data/raw/` â†’ Original dataset  
- `data/processed/` â†’ Cleaned & feature-engineered dataset  

Generated:

- `clean_model_dataset.csv` â€“ Model-ready dataset  

---

### ğŸ““ Reproducible Pipeline

Created:

- `notebooks/phase1_data_engineering.ipynb`

This notebook:

- Performs data cleaning  
- Applies feature engineering logic  
- Generates processed dataset  
- Ensures full reproducibility of Phase 1  

---

### âœ… Output of Phase 1

A structured, validated, and reproducible dataset ready for predictive modeling in Phase 2.

---

## ğŸ¤– Phase 2 â€“ Delay Prediction Model & Risk Scoring

### ğŸ¯ Objective
Develop a machine learning model to predict **delivery delay probability** (`delay_probability`) to serve as the foundation for structured risk classification.

---

### ğŸ§ª Model Benchmarking
Evaluated multiple models:

- Logistic Regression  
- Random Forest  
- Gradient Boosting  
- KNN  
- SVM  
- XGBoost  

Tuning performed using 5-fold cross-validation with ROC-AUC as the primary metric.

---

### ğŸ† Final Model
**Selected Model:** Logistic Regression  
Best Parameters:
- C = 0.01  
- penalty = l2  
- solver = lbfgs  
- max_iter = 5000  

Chosen for balanced F1 score, stable ROC-AUC, interpretability, and deployment simplicity.

---

### ğŸ“ˆ Final Performance (Threshold = 0.6)

- Accuracy â‰ˆ 0.77  
- Precision â‰ˆ 0.98  
- Recall â‰ˆ 0.61  
- F1 Score â‰ˆ 0.75  
- ROC-AUC â‰ˆ 0.80  

---

### ğŸ“¦ Artifacts Generated
- `models/delay_model.pkl`
- `models/scaler.pkl`
- `data/processed/dataset_with_delay_probability.csv`

This completes the predictive layer of the Smart Logistics Decision System.

---

## âš–ï¸ Phase 3 â€“ Risk Classification & Decision Layer

### ğŸ¯ Objective
Transform predicted delay probabilities into structured operational risk levels and integrate business rule overrides to create a robust decision engine.

---

### ğŸ”„ Architecture Overview

Phase 3 converts:

Model Output â†’ Risk Tier â†’ Rule Overrides â†’ Final Risk Level

Pipeline:

1. `delay_probability` (from Phase 2 model)
2. Probability-to-risk mapping
3. Rule-based escalation
4. Final operational risk classification

This creates a hybrid ML + domain-intelligence system.

---

### ğŸ“Š Step 3.1 â€“ Probability â†’ Risk Mapping

Delay probability is converted into structured risk tiers:

- `< 0.40` â†’ Low  
- `0.40 â€“ 0.70` â†’ Medium  
- `> 0.70` â†’ High  
- `> 0.85` â†’ Critical  

Implemented via:

`get_risk_level(probability)`

Generated column:

`ml_risk_level`

This ensures model output becomes actionable.

---

### ğŸ¢ Step 3.2 â€“ Rule-Based Risk Overrides

To enhance robustness, business logic rules were introduced.

#### Rule 1 â€“ Weather-Traffic Escalation
If:
- Precipitation (mm) > 15  
- Traffic_Status_Heavy == 1  

â†’ Risk escalated to **Critical**

#### Rule 2 â€“ Asset Stress Escalation
If:
- Asset_Utilization > 90  

â†’ Risk escalated to **High**

Final risk level is determined as the maximum severity between:

- ML-derived risk  
- Rule-based escalation  

Generated column:

`final_risk_level`

---

### ğŸ§  Why Combine ML + Rule Logic?

Pure ML models may miss rare but operationally dangerous scenarios.

By integrating domain rules:

- Critical weather conditions are never ignored  
- Fleet stress is proactively managed  
- Operational safety is prioritized  
- Decision robustness increases  

This design reflects real-world logistics intelligence systems.

---

### ğŸ“ˆ Output

Generated:

`data/processed/dataset_with_risk_levels.csv`

Risk distribution example:

- Medium â‰ˆ 32%  
- High â‰ˆ 24%
- Critical â‰ˆ 24%  
- Low â‰ˆ 20%

Phase 3 completes the structured risk engine of the Smart Logistics Decision System.

---

## ğŸš¦ Phase 4 â€“ Risk-Driven Decision Engine

### ğŸ¯ Objective
Translate structured risk levels into operational actions using a mathematically grounded and system-aware decision framework.

Phase 4 connects predictive intelligence (Phases 2â€“3) to executable logistics decisions.

---

### ğŸ” Risk â†’ Action Mapping

Risk levels are converted into structured operational actions:

- **Low** â†’ `A_Normal`
- **Medium** â†’ `B_Monitor`
- **High** â†’ `C_Reroute_Notify`
- **Critical** â†’ `D_Reroute_Notify_Redistribute`
- **High + Asset_Utilization > 90%** â†’ Escalated to `D_Reroute_Notify_Redistribute`

This ensures fleet stress conditions can trigger escalation even when base risk is High.

---

### â± Dynamic Baseline ETA Modeling

Baseline ETA is computed mathematically, not heuristically:

- `operational_base_time` derived from mean waiting time
- `traffic_delay_factor` computed using average delay probability grouped by traffic level
- `baseline_eta` calculated as:

Baseline ETA = operational_base_time Ã— traffic_delay_factor

This ensures ETA reflects real model-driven traffic impact rather than arbitrary assumptions.

---

### ğŸ›£ Simulated Route Optimization

When rerouting is triggered:

- Improvement factor calculated from difference between original traffic factor and clear-traffic factor
- Optimized ETA adjusted proportionally
- Ensured optimized ETA logically falls between heavy and clear traffic bounds
- No artificial traffic-status reassignment

This preserves mathematical consistency while simulating realistic route improvement.

---

### ğŸ“Š Utilization Impact Analysis

Fleet stress behavior modeled analytically:

- Asset_Utilization bucketed into:
  - (0â€“70]
  - (70â€“90]
  - (90â€“100]

- Computed `stress_gap` between high and medium utilization segments
- Redistribution logic applied only if impact exceeds defined threshold
- Redistribution skipped if operational improvement is negligible

This prevents unnecessary fleet movements and avoids overreaction.

---

### ğŸ’¬ AI-Generated Customer Notifications (yet to do)

When action includes `"Notify"`:

- Structured message automatically generated
- Context-aware (weather, traffic, utilization stress)

Example output:
"Due to heavy traffic conditions, your shipment has been proactively rerouted to minimize delay."

---

### ğŸ§  Architectural Significance

Phase 4 transforms the system into a full decision intelligence pipeline:

Model â†’ Probability â†’ Risk â†’ Action â†’ ETA Adjustment â†’ Notification

This completes the operational decision layer of the Smart Logistics Decision System.

---

## ğŸš€ Phase 5 â€“ Production Deployment & Mathematical Decision Engine

Phase 5 transforms the Smart Logistics System into a modular, deployment-ready, mathematically grounded decision engine.

This phase replaces notebook-level experimentation with structured production architecture.

---

### ğŸ§© 1ï¸âƒ£ Modular Decision Engine

Converted experimental logic into a reusable module:

`decision_engine.py`

Implemented reusable functions:

- `classify_risk()`
- `get_action()`
- `calculate_baseline_eta()`
- `calculate_optimized_eta()`
- `generate_notification()`

Key Improvements:

- Removed all hardcoded constants
- All thresholds and calculations are dataset-driven
- Deterministic outputs
- Fully reusable architecture

---

### ğŸ“ 2ï¸âƒ£ Data-Driven ETA Computation (Mathematical Formulation)

#### Operational Base Time

\[
operational\_base\_time = \text{mean}(Waiting\_Time)
\]

#### Traffic Impact

\[
traffic\_impact(level) =
\text{mean}(delay\_probability \mid traffic\_level = level)
\]

#### Traffic Delay Factor

\[
traffic\_delay\_factor = traffic\_impact[traffic\_level]
\]

#### Baseline ETA

\[
baseline\_eta =
operational\_base\_time + (traffic\_delay\_factor \times operational\_base\_time)
\]

Simplified:

\[
baseline\_eta =
operational\_base\_time \times (1 + traffic\_delay\_factor)
\]

This ensures ETA reflects real statistical traffic behavior rather than arbitrary assumptions.

---

### ğŸ›£ 3ï¸âƒ£ Mathematical Reroute Optimization

Clear traffic reference:

\[
clear\_factor = \min(traffic\_impact)
\]

Improvement formula (50% congestion recovery):

\[
optimized\_factor =
original\_factor
- 0.5 \times (original\_factor - clear\_factor)
\]

Optimized ETA:

\[
optimized\_eta =
operational\_base\_time
+ (optimized\_factor \times operational\_base\_time)
\]

Guarantee:

\[
clear < optimized\_heavy < heavy
\]

No arbitrary ETA subtraction is used.

All improvements are mathematically bounded.

---

### âš–ï¸ 4ï¸âƒ£ Risk â†’ Action Mapping

- **Low** â†’ `A_Normal`
- **Medium** â†’ `B_Monitor`
- **High** â†’ `C_Reroute_Notify`
- **High + Utilization > 90%** â†’ `D_Reroute_Notify_Redistribute`
- **Critical** â†’ `D_Reroute_Notify_Redistribute`

Escalation logic integrates both predictive and operational stress signals.

---

### ğŸ“Š 5ï¸âƒ£ Fleet Utilization Stress Analysis

Utilization buckets:

- (0â€“70]
- (70â€“90]
- (90â€“100]

Average delay per bucket:

\[
utilization\_impact =
\text{mean}(delay\_probability \mid utilization\_bucket)
\]

Stress gap:

\[
stress\_gap =
high\_util\_factor - medium\_util\_factor
\]

Redistribution condition:

\[
if \; stress\_gap < threshold \Rightarrow
\text{Skip Redistribution}
\]

Fleet redistribution is data-validated, not forced.

---

### ğŸ’¬ 6ï¸âƒ£ AI-Based Customer Notification Layer

Dynamic notification logic based on:

- Risk level
- Traffic condition
- Baseline ETA
- Optimized ETA

Decision logic:

If:
\[
optimized\_eta < baseline\_eta
\]
â†’ Message communicates improvement.

Else:
â†’ Message communicates monitoring status.

This ensures consistent and context-aware communication.

---

### ğŸ–¥ 7ï¸âƒ£ Streamlit Production Deployment

Implemented `app.py` for real-time inference.

Key Deployment Features:

- Integrated `delay_model.pkl` and `scaler.pkl`
- Used `scaler.feature_names_in_` to reconstruct exact training feature order
- Auto-filled non-user features using dataset means
- Eliminated feature mismatch and casing errors
- Guaranteed inference consistency with training pipeline

Frontend Displays:

- Delay Probability
- Risk Level
- Action Taken
- Baseline ETA
- Optimized ETA
- Final Customer Notification

---

### ğŸ§  8ï¸âƒ£ Technical Advancements

- Full feature alignment with training metadata
- Zero hardcoded ETA adjustments
- Deterministic mathematical optimization
- Modular production architecture
- Deployment-ready system structure

---

### ğŸ Architectural Outcome

The system now operates as:

\[
Input
\rightarrow Model
\rightarrow Probability
\rightarrow Risk
\rightarrow Action
\rightarrow ETA Optimization
\rightarrow Notification
\]

Phase 5 completes the transition from experimental ML project to production-grade intelligent logistics decision system.
